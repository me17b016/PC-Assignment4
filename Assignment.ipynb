{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pj8jKiAEUWzA",
        "outputId": "176d48fd-73b5-4b1d-f207-9c125ea30de4"
      },
      "source": [
        "!nvcc --version"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2019 NVIDIA Corporation\n",
            "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
            "Cuda compilation tools, release 10.1, V10.1.243\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bZs0ZO8YIf4",
        "outputId": "14e2ee11-6d56-4dbb-cab9-f1a9fad3281a"
      },
      "source": [
        "!pip install git+git://github.com/andreinechaev/nvcc4jupyter.git\r\n",
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning git://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-ntcv4gk9\n",
            "  Running command git clone -q git://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-ntcv4gk9\n",
            "Requirement already satisfied (use --upgrade to upgrade): NVCCPlugin==0.0.2 from git+git://github.com/andreinechaev/nvcc4jupyter.git in /usr/local/lib/python3.6/dist-packages\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.2-cp36-none-any.whl size=4308 sha256=2de32239cc08bae9d76a3cdcfcff83ecec5f2264490721ac25caf47a96b7aca7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-25uusayr/wheels/10/c2/05/ca241da37bff77d60d31a9174f988109c61ba989e4d4650516\n",
            "Successfully built NVCCPlugin\n",
            "The nvcc_plugin extension is already loaded. To reload it, use:\n",
            "  %reload_ext nvcc_plugin\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dxc8xV3MXehl",
        "outputId": "7e36fff6-24f5-481f-c36b-fe606a90c023"
      },
      "source": [
        "%%cu\r\n",
        "// Problem 1\r\n",
        "#include <iostream>\r\n",
        "using namespace std;\r\n",
        "\r\n",
        "const short N = 16;\r\n",
        "\r\n",
        "__managed__ int a[N];\r\n",
        "\r\n",
        "__global__ void sum() {\r\n",
        "\tconst int tid = threadIdx.x;\r\n",
        "\r\n",
        "\tauto step_size = 1;\r\n",
        "\tint number_of_threads = blockDim.x;\r\n",
        "\r\n",
        "\twhile (number_of_threads > 0)\r\n",
        "\t{\r\n",
        "\t\tif (tid < number_of_threads)\r\n",
        "\t\t{\r\n",
        "\t\t\tconst auto st = tid * step_size * 2;\r\n",
        "\t\t\tconst auto en = st + step_size;\r\n",
        "      if (st < N && en < N)\r\n",
        "\t\t\ta[st] += a[en];\r\n",
        "\t\t}\r\n",
        "\r\n",
        "\t\tstep_size <<= 1; \r\n",
        "\t\tnumber_of_threads >>= 1;\r\n",
        "\t}\r\n",
        "}\r\n",
        "\r\n",
        "int main() {\r\n",
        "  int n = N;\r\n",
        "  if ((n != 1) && (n & (n - 1))) {\r\n",
        "      n |= n >> 1;\r\n",
        "      n |= n >> 2;\r\n",
        "      n |= n >> 4;\r\n",
        "      n |= n >> 8;\r\n",
        "      n |= n >> 16;\r\n",
        "      n = n + 1;\r\n",
        "  }\r\n",
        "\r\n",
        "\tfor (int i = 0; i < N; i++) a[i] = 1;\r\n",
        "\tsum <<<1, n / 2 >>>();\r\n",
        "  cudaDeviceSynchronize();\r\n",
        "  int result = a[0];\r\n",
        "\tcout << \"Sum is \" << result << endl;\r\n",
        "\treturn 0;\r\n",
        "}"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sum is 16\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBFlk4ptgCCw",
        "outputId": "7485013d-47a0-4995-fd1e-5a1d68a6c1e1"
      },
      "source": [
        "%%cu\r\n",
        "// Problem 2\r\n",
        "#include <stdio.h>\r\n",
        "\r\n",
        "const short N = 10;\r\n",
        "\r\n",
        "__managed__ int a[N], b[N], c[N];\r\n",
        "\r\n",
        "__global__ void Vector_Addition () {\r\n",
        "      //Get the id of thread within a block\r\n",
        "      \r\n",
        "      unsigned short tid = blockDim.x * blockIdx.x + threadIdx.x;\r\n",
        "\r\n",
        "     // check the boundry condition for the threads\r\n",
        "      if (tid < N) c[tid] = a[tid] + b[tid];\r\n",
        "\r\n",
        "}\r\n",
        "\r\n",
        "\r\n",
        "int main (){\r\n",
        "      for (int i = 0; i < N; i++){\r\n",
        "            a[i] = -i ;\r\n",
        "            b[i] = i*i ; \r\n",
        "      }\r\n",
        "      int threadsPerBlock = 256;\r\n",
        "      int blocksPerGrid =(N + threadsPerBlock - 1) / threadsPerBlock;\r\n",
        "      Vector_Addition <<<blocksPerGrid, threadsPerBlock>>> ( ) ;\r\n",
        "      cudaDeviceSynchronize();\r\n",
        "\r\n",
        "      for ( int i = 0; i<N; i++ )\r\n",
        "      printf(\"%d + %d = %d\\n\", a[i] , b[i] , c[i]);\r\n",
        "\r\n",
        "      return 0 ;\r\n",
        "}\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 + 0 = 0\n",
            "-1 + 1 = 0\n",
            "-2 + 4 = 2\n",
            "-3 + 9 = 6\n",
            "-4 + 16 = 12\n",
            "-5 + 25 = 20\n",
            "-6 + 36 = 30\n",
            "-7 + 49 = 42\n",
            "-8 + 64 = 56\n",
            "-9 + 81 = 72\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYvaYz6YrKhS",
        "outputId": "fc4fcf61-12c8-472d-aae9-41d52d0db532"
      },
      "source": [
        "%%cu\r\n",
        "// Problem 3\r\n",
        "#include <iostream>\r\n",
        "using namespace std;\r\n",
        "\r\n",
        "const int m = 3, n = 2, p = 4;\r\n",
        "__managed__ int a[m * n], b[n * p], c[m * p];\r\n",
        "\r\n",
        "__global__ void MatrixMultiply() {\r\n",
        "  int row = blockIdx.x * p + threadIdx.x;\r\n",
        "  int col = blockIdx.y * m + threadIdx.y;\r\n",
        "  \r\n",
        "  if(row < m && col < p) {\r\n",
        "    //printf(\"%d %d\\n\", row, col);\r\n",
        "    float tem = 0;\r\n",
        "    for(int k = 0; k < n; k++) {\r\n",
        "        tem += a[row * n + k] * b[k * p + col];\r\n",
        "    }\r\n",
        "    c[row * p + col] = tem;\r\n",
        "  }    \r\n",
        "}\r\n",
        "\r\n",
        "int main() {\r\n",
        "  for (int i = 0; i < m * n; i++) a[i] = rand() % 50;  \r\n",
        "  for (int i = 0; i < n * p; i++) b[i] = rand() % 50;\r\n",
        "  cout << \"Matrix A:\\n\";\r\n",
        "  for (int i = 0; i < m; i++) {\r\n",
        "      for (int j = 0; j < n; j++) cout << a[i * n + j] << ' ';\r\n",
        "      cout << '\\n';\r\n",
        "  }  \r\n",
        "  cout << \"Matrix B:\\n\";\r\n",
        "  for (int i = 0; i < n; i++) {\r\n",
        "      for (int j = 0; j < p; j++) cout << b[i * p + j] << ' ';\r\n",
        "      cout << '\\n';\r\n",
        "  } \r\n",
        "  dim3 threadsPerBlock(m, p);\r\n",
        "  dim3 blocksPerGrid(1, 1);\r\n",
        "  if (m * p > 512){\r\n",
        "    threadsPerBlock.x = 512;\r\n",
        "    threadsPerBlock.y = 512;\r\n",
        "    blocksPerGrid.x = ceil(double(m)/double(threadsPerBlock.x));\r\n",
        "    blocksPerGrid.y = ceil(double(p)/double(threadsPerBlock.y));\r\n",
        "  }\r\n",
        "  MatrixMultiply<<<blocksPerGrid,threadsPerBlock>>>();\r\n",
        "  cudaDeviceSynchronize();\r\n",
        "  cout << \"Matrix C:\\n\";\r\n",
        "  for (int i = 0; i < m; i++) {\r\n",
        "      for (int j = 0; j < p; j++) cout << c[i * p + j] << ' ';\r\n",
        "      cout << '\\n';\r\n",
        "  } \r\n",
        "}"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Matrix A:\n",
            "33 36 \n",
            "27 15 \n",
            "43 35 \n",
            "Matrix B:\n",
            "36 42 49 21 \n",
            "12 27 40 9 \n",
            "Matrix C:\n",
            "1620 2358 3057 1017 \n",
            "1152 1539 1923 702 \n",
            "1968 2751 3507 1218 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-sefeJjDqlH",
        "outputId": "b5c16710-eba1-4a0d-e13d-3e2d2a86c7a8"
      },
      "source": [
        "%%cu\r\n",
        "// Problem 5\r\n",
        "#include<iostream>\r\n",
        "using namespace std;\r\n",
        "\r\n",
        "__managed__ int N = 10, E = 0;\r\n",
        "// Kernel definition\r\n",
        "__global__ void BFS(int* DV_a, int* DE_a, int* DC, bool* DF, bool* DX) {\r\n",
        "    \r\n",
        "    int tid = threadIdx.x;\r\n",
        "    if(tid < N) {\r\n",
        "        if(DF[tid]) {\r\n",
        "            DF[tid] = false, DX[tid] = true;\r\n",
        "            int st = DV_a[tid], en = 2 * E;\r\n",
        "            //printf(\"%d %d\\n\", st, en);\r\n",
        "            if(tid < N - 1) en = DV_a[tid + 1];\r\n",
        "            for(int i = st; i < en; i++) {\r\n",
        "                int nid = DE_a[i];\r\n",
        "                if(!DX[nid]) {\r\n",
        "                    DC[nid] = DC[tid] + 1;\r\n",
        "                    DF[nid] = true;\r\n",
        "                }\r\n",
        "            }\r\n",
        "        }\r\n",
        "    }\r\n",
        "}\r\n",
        "\r\n",
        "int main() {\r\n",
        "  int G[N][N];\r\n",
        "  // Generating Graph\r\n",
        "  for (int i = 0; i < N; i++) {\r\n",
        "      for (int j = i; j < N; j++) {\r\n",
        "          if (i == j) G[i][j] = 0;\r\n",
        "          else G[i][j] = G[j][i] = rand() % 2, E += G[i][j];\r\n",
        "      }\r\n",
        "  }    \r\n",
        "  int V_a[N], E_a[2 * E];\r\n",
        "  int t = 0;\r\n",
        "  for (int i = 0; i < N; i++) {\r\n",
        "      V_a[i] = t;\r\n",
        "      for (int j = 0; j < N; j++) {\r\n",
        "          if (G[i][j]) E_a[t] = j, t++;\r\n",
        "      }\r\n",
        "  }\r\n",
        "\r\n",
        "  int C[N]; bool F[N], X[N];\r\n",
        "  for(int i = 0; i < N; i++) {\r\n",
        "      C[i] = INT_MAX;\r\n",
        "      F[i] = X[i] = false;\r\n",
        "  }\r\n",
        "  // source\r\n",
        "  int s = 2;\r\n",
        "  C[s] = 0, F[s] = true;\r\n",
        "  cout << E << '\\n';\r\n",
        "  int *DV_a, *DE_a, *DC;\r\n",
        "  bool *DF, *DX;\r\n",
        "  cudaMalloc((void**) & DV_a, N * sizeof(int));\r\n",
        "  cudaMalloc((void**) & DE_a, 2 * E * sizeof(int));\r\n",
        "  cudaMalloc((void**) & DC, N * sizeof(int));\r\n",
        "  cudaMalloc((void**) & DF, N * sizeof(bool));\r\n",
        "  cudaMalloc((void**) & DX, N * sizeof(bool));\r\n",
        "    \r\n",
        "  cudaMemcpy(DV_a, V_a, N * sizeof(int), cudaMemcpyHostToDevice);\r\n",
        "  cudaMemcpy(DE_a, E_a, 2 * E * sizeof(int), cudaMemcpyHostToDevice);\r\n",
        "  cudaMemcpy(DC, C, N * sizeof(int), cudaMemcpyHostToDevice);\r\n",
        "  cudaMemcpy(DF, F, N * sizeof(bool), cudaMemcpyHostToDevice);\r\n",
        "  cudaMemcpy(DX, X, N * sizeof(bool), cudaMemcpyHostToDevice);\r\n",
        "  int u = 10;\r\n",
        "while (1) {\r\n",
        "    int ok = 0;\r\n",
        "    BFS<<<1, N>>>(DV_a, DE_a, DC, DF, DX);\r\n",
        "    cudaDeviceSynchronize();\r\n",
        "    cudaMemcpy(F, DF, N * sizeof(bool), cudaMemcpyDeviceToHost);\r\n",
        "    for(int i = 0; i < N; i++) {\r\n",
        "        if(F[i]) {\r\n",
        "            ok = 1;\r\n",
        "            break;\r\n",
        "        }\r\n",
        "    }\r\n",
        "      if(!ok) break;\r\n",
        "}\r\n",
        "    cudaMemcpy(C, DC, N * sizeof(int), cudaMemcpyDeviceToHost);\r\n",
        "    cout << \"Distances: \\n\";\r\n",
        "    for (auto to : C) cout << to << ' ';\r\n",
        "    cudaFree(DV_a);\r\n",
        "    cudaFree(DE_a);\r\n",
        "    cudaFree(DC);\r\n",
        "    cudaFree(DF);\r\n",
        "    cudaFree(DX);\r\n",
        "    return 0;\r\n",
        "}\r\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "25\n",
            "Distances: \n",
            "2 1 0 2 2 2 1 2 1 1 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guvwazsDXAcK",
        "outputId": "dee13017-7a30-483d-b110-40104aa01810"
      },
      "source": [
        "%%cu\r\n",
        "// Problem 5\r\n",
        "#include<iostream>\r\n",
        "using namespace std;\r\n",
        "\r\n",
        "__managed__ int N = 6, E = 0;\r\n",
        "// Kernel definition\r\n",
        "__global__ void SSSP_KERNEL1 (int* DV_a, int* DE_a, int* DW, bool* DM, int* DC, int* DU) {\r\n",
        "  int tid = threadIdx.x;\r\n",
        "  if (tid < N) {\r\n",
        "      if (DM[tid]) {\r\n",
        "          DM[tid] = false;\r\n",
        "          int st = DV_a[tid], en = 2 * E;\r\n",
        "          if (tid < N - 1) en = DV_a[tid + 1];\r\n",
        "          for (int i = st; i < en; i++) {\r\n",
        "              int nid = DE_a[i];\r\n",
        "              if (DU[nid] > DC[tid] + DW[nid]) {\r\n",
        "                  DU[nid] = DC[tid] + DW[nid];\r\n",
        "              }\r\n",
        "          }\r\n",
        "      }\r\n",
        "  }    \r\n",
        "}\r\n",
        "\r\n",
        "__global__ void SSSP_KERNEL2 (int* DV_a, int* DE_a, int* DW, bool* DM, int* DC, int* DU) {\r\n",
        "  int tid = threadIdx.x;\r\n",
        "  if (tid < N) {\r\n",
        "      if (DC[tid] > DU[tid]) {\r\n",
        "          DC[tid] = DU[tid];\r\n",
        "          DM[tid] = true;\r\n",
        "      }\r\n",
        "      DU[tid] = DC[tid];\r\n",
        "  }    \r\n",
        "}\r\n",
        "\r\n",
        "int main() {\r\n",
        "  int G[N][N];\r\n",
        "  // Generating Graph\r\n",
        "  for (int i = 0; i < N; i++) {\r\n",
        "      for (int j = i; j < N; j++) {\r\n",
        "          if (i == j) G[i][j] = 0;\r\n",
        "          else G[i][j] = G[j][i] = rand() % 50;\r\n",
        "          if (G[i][j]) E++;\r\n",
        "      }\r\n",
        "  }    \r\n",
        "  int V_a[N], E_a[2 * E], W[2 * E];\r\n",
        "  int t = 0;\r\n",
        "  for (int i = 0; i < N; i++) {\r\n",
        "      V_a[i] = t;\r\n",
        "      for (int j = 0; j < N; j++) {\r\n",
        "          if (G[i][j]) E_a[t] = j, W[t] = G[i][j], t++;\r\n",
        "      }\r\n",
        "  }\r\n",
        "  for (int i = 0; i < N; i++) {\r\n",
        "      for (int j = 0; j < N; j++) cout << G[i][j] << ' ';\r\n",
        "      cout << '\\n';\r\n",
        "  }\r\n",
        "  int C[N], U[N]; bool M[N];\r\n",
        "  for(int i = 0; i < N; i++) {\r\n",
        "      C[i] = U[i] = INT_MAX;\r\n",
        "      M[i] = false;\r\n",
        "  }\r\n",
        "  // source\r\n",
        "  int s = 2;\r\n",
        "  C[s] = U[s] = 0, M[s] = true;\r\n",
        "\r\n",
        "  cout << E << '\\n';\r\n",
        "\r\n",
        "  int *DV_a, *DE_a, *DC, *DW, *DU;\r\n",
        "  bool *DM;\r\n",
        "  cudaMalloc((void**) & DV_a, N * sizeof(int));\r\n",
        "  cudaMalloc((void**) & DE_a, 2 * E * sizeof(int));\r\n",
        "  cudaMalloc((void**) & DC, N * sizeof(int));\r\n",
        "  cudaMalloc((void**) & DW, 2 * E * sizeof(int));\r\n",
        "  cudaMalloc((void**) & DU, N * sizeof(int));\r\n",
        "  cudaMalloc((void**) & DM, N * sizeof(bool));\r\n",
        "    \r\n",
        "  cudaMemcpy(DV_a, V_a, N * sizeof(int), cudaMemcpyHostToDevice);\r\n",
        "  cudaMemcpy(DE_a, E_a, 2 * E * sizeof(int), cudaMemcpyHostToDevice);\r\n",
        "  cudaMemcpy(DC, C, N * sizeof(int), cudaMemcpyHostToDevice);\r\n",
        "  cudaMemcpy(DW, W, 2 * E * sizeof(int), cudaMemcpyHostToDevice);\r\n",
        "  cudaMemcpy(DU, U, N * sizeof(int), cudaMemcpyHostToDevice);\r\n",
        "  cudaMemcpy(DM, M, N * sizeof(bool), cudaMemcpyHostToDevice);\r\n",
        "\r\n",
        "  int u = 10;\r\n",
        "  while (1) {\r\n",
        "    int ok = 0;\r\n",
        "    SSSP_KERNEL1<<<1, N>>>(DV_a, DE_a, DW, DM, DC, DU);\r\n",
        "    cudaDeviceSynchronize();\r\n",
        "    SSSP_KERNEL2<<<1, N>>>(DV_a, DE_a, DW, DM, DC, DU);\r\n",
        "    cudaDeviceSynchronize();\r\n",
        "    cudaMemcpy(M, DM, N * sizeof(bool), cudaMemcpyDeviceToHost);\r\n",
        "    for(int i = 0; i < N; i++) {\r\n",
        "        if(M[i]) {\r\n",
        "            ok = 1;\r\n",
        "            break;\r\n",
        "        }\r\n",
        "    }\r\n",
        "    if(!ok) break;\r\n",
        "  }\r\n",
        "    cudaMemcpy(C, DC, N * sizeof(int), cudaMemcpyDeviceToHost);\r\n",
        "    cout << \"Distances: \\n\";\r\n",
        "    for (auto to : C) cout << to << ' ';\r\n",
        "    cudaFree(DV_a);\r\n",
        "    cudaFree(DE_a);\r\n",
        "    cudaFree(DC);\r\n",
        "    cudaFree(DW);\r\n",
        "    cudaFree(DU);\r\n",
        "    cudaFree(DM);\r\n",
        "    return 0;\r\n",
        "}"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 33 36 27 15 43 \n",
            "33 0 35 36 42 49 \n",
            "36 35 0 21 12 27 \n",
            "27 36 21 0 40 9 \n",
            "15 42 12 40 0 13 \n",
            "43 49 27 9 13 0 \n",
            "15\n",
            "Distances: \n",
            "33 36 0 15 43 33 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzp0B2GkpfmM",
        "outputId": "f15845f4-d4a6-4931-9556-fcac77b6b288"
      },
      "source": [
        "%%cu\r\n",
        "// Problem 7\r\n",
        "#include <iostream>\r\n",
        "#include <algorithm>\r\n",
        "#include <thrust/host_vector.h>\r\n",
        "#include <thrust/device_vector.h>\r\n",
        "#include <thrust/sort.h>\r\n",
        "#include<thrust/copy.h>\r\n",
        "using namespace std;\r\n",
        "\r\n",
        "const int N = 17;\r\n",
        "\r\n",
        "int main() {\r\n",
        "  thrust::host_vector<int> h(N);\r\n",
        "  for (int i = 0; i < N; i++) h[i] = rand() % 50;\r\n",
        "  for (auto to : h) cout << to << ' ';\r\n",
        "  cout << '\\n';\r\n",
        "  thrust::device_vector<int> d = h;\r\n",
        "  thrust::sort(d.begin(), d.end());\r\n",
        "  thrust::copy(d.begin(), d.end(), h.begin());\r\n",
        "  for (auto to : h) cout << to << ' ';\r\n",
        "  cout << '\\n';\r\n",
        "  return 0;\r\n",
        "}"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33 36 27 15 43 35 36 42 49 21 12 27 40 9 13 26 40 \n",
            "9 12 13 15 21 26 27 27 33 35 36 36 40 40 42 43 49 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}